\section{Conclusion}

Cette section vise à établir un ensemble de conclusions concernant la mise en \oe uvre de méthodes de classification de sentiments pour de courts textes en anglais. Tout d’abord, il est important de souligner l’analyse réalisée durant la phase préliminaire du jeu de données et de ses caractéristiques principales. À partir de cette analyse, on observe que, compte tenu des informations d’entraînement disponibles, la variable d’intérêt principale pour entraîner ce type de classifieur est sans ambiguïté le texte prétraité après suppression des stopwords. En effet, la distribution des classes vis-à-vis des autres variables du jeu de données reste soit constante (comme pour les tranches d’âge), soit peut induire un risque accru de mémorisation de motifs non pertinents, car les éléments de chaque classe au sein de ces catégories ne sont pas représentatifs de l’ensemble de la collecte (comme pour la variable pays).

Concernant l’entraînement des modèles classiques d’apprentissage automatique, les résultats atteignent de bonnes performances, principalement grâce à l’évaluation de multiples pipelines combinant un vectoriseur et un classifieur, ainsi qu’aux variations de leurs grilles d’hyperparamètres. Cela conduit à un total de 956 modèles entraînés, dont les meilleures configurations sont sélectionnées. De plus, parmi les trois types de représentations, les meilleurs résultats sont obtenus avec le SVM, la régression logistique et la forêt aléatoire, avec de légers avantages en F1 et en accuracy pour la forêt aléatoire dans la plupart des cas. Néanmoins, des modèles tels que la régression logistique et le SVM sont plus intelligibles et interprétables. Par conséquent, et considérant que les différences de performance entre la forêt aléatoire et la régression logistique / le SVM ne sont pas suffisamment marquées pour conclure que la forêt aléatoire est la meilleure option en NLP, il est important de noter que, malgré des métriques légèrement supérieures, la forêt aléatoire implique un coût d’entraînement sensiblement plus élevé en temps de calcul et en ressources.

Bien que, dans le cas des modèles classiques, l’importance de la méthode de vectorisation et de son choix soit abordée, l’utilisation d’une recherche d’hyperparamètres permet de limiter cet effet lors de la sélection d’un pipeline, puisque les paramètres du vectoriseur font partie intégrante de la procédure de recherche. En revanche, dans le cas des MLP, le nombre plus réduit de configurations candidates, l’influence de chaque type de vectorisation sur la structure du réseau, ainsi que l’intégration d’embeddings BERT figés avant l’entraînement, conduisent à considérer non seulement le meilleur modèle, mais plus largement le meilleur pipeline, incluant à la fois la représentation et la classification.

Lors de l’analyse des résultats de test des MLP entraînés avec des entrées TF--IDF au niveau des caractères, l’écart entre les performances d’entraînement et de test indique une forte capacité d’ajustement et, par conséquent, un risque élevé de surapprentissage. Des modifications de l’architecture du réseau, principalement en termes de largeur des couches et de régularisation, compte tenu de la matrice creuse compressée en entrée, ne se traduisent pas toujours par des améliorations proportionnelles sur le jeu de test, car le risque de surapprentissage augmente. À l’inverse, l’utilisation d’embeddings BERT figés, bien qu’elle présente des performances attendues avec un nombre de paramètres inférieur à celui des modèles TF--IDF caractères, bénéficie du caractère dense de la matrice d’entrée et d’une complexité nettement réduite du classifieur par rapport aux données d’entraînement. Cela rend les structures plus simples associées à cette représentation particulièrement attractives, comme dans le cas d’une couche de décision unique pour classifier les vecteurs produits par BERT. En effet, pour ce type de représentation, l’augmentation de la profondeur et de la complexité globale du réseau peut être associée à une dégradation des performances sur le jeu de test, précisément parce que, compte tenu des propriétés de BERT et de la densité d’information des embeddings, la structure du réseau et le nombre de paramètres nécessaires peuvent rester limités.

Après l’entraînement des MLP, les modèles classiques, en combinaison avec la vectorisation TF--IDF au niveau des caractères, conservent de meilleures performances que les MLP, y compris ceux utilisant des embeddings BERT, pour deux raisons principales. La première est la rigueur de la recherche d’hyperparamètres réalisée pour les modèles classiques. La seconde est que, pour les modèles basés sur des embeddings BERT, il existe encore une marge d’amélioration, en particulier pour la structure la plus conservatrice qui présente de meilleures performances et un risque réduit de surapprentissage ; cette amélioration est rendue possible par le fine-tuning via LoRA, qui permet d’adapter le processus de représentation au domaine spécifique du jeu de données d’entraînement. Les résultats obtenus montrent que, parmi l’ensemble des modèles évalués, le modèle BERT affiné avec LoRA atteint la meilleure performance en termes de F1 et d’accuracy avec une marge notable ; il constitue donc une structure fortement recommandée pour développer des modèles de classification de courts textes fondés sur la polarité ou le sentiment.
