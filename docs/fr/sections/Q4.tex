\section{Q4 : Analyse comparative avec des grands mod\`eles de langage (LLM)}

Cette analyse compare la meilleure architecture bas\'ee sur BERT \`a un grand mod\`ele de langage moderne. L'objectif est d'\'evaluer si un mod\`ele g\'en\'eratif g\'en\'eraliste, utilis\'e uniquement en inf\'erence, peut rivaliser avec un encodeur sp\'ecialis\'e ayant \'et\'e adapt\'e \`a la t\^ache.

\subsection{M\'ethodologie : inf\'erence g\'en\'erative}

Le mod\`ele gemma-3-4b-it est retenu (instruction-tuned, $\sim$4 milliards de param\`etres). Contrairement \`a la baseline BERT de cette partie --- embeddings BERT fig\'es avec une t\^ete lin\'eaire (\texttt{LinearHead(768$\rightarrow$3)}) --- le LLM est \'evalu\'e via \emph{few-shot prompting} avec l'API Google GenAI, sans mise \`a jour de param\`etres.

Le protocole est d\'efini comme suit :
\begin{itemize}
    \item \textbf{Prompt engineering :} le mod\`ele est explicitement instruit \`a se comporter comme un expert en analyse de sentiment.
    \item \textbf{Contexte few-shot :} trois exemples annot\'es (un par classe : Positive, Negative, Neutral) sont fournis avant la requ\^ete cible.
    \item \textbf{Contraintes de sortie :} la g\'en\'eration est contrainte \`a un label mono-mot mapp\'e vers les classes num\'eriques ($0,1,2$).
    \item \textbf{Sous-ensemble d'\'evaluation :} pour des raisons de latence et de quotas API, l'\'evaluation est men\'ee sur 1\,000 exemples repr\'esentatifs du test.
\end{itemize}

\subsection{\'Evaluation de performance}

Les capacit\'es g\'en\'eratives de Gemma sont compar\'ees au mod\`ele \texttt{BERT Linear Head}, qui pr\'esente la meilleure performance parmi les configurations BERT test\'ees pr\'ec\'edemment.

\subsubsection{R\'esultats LLM (Gemma-3-4b-it)}
La Fig.~\ref{fig:gemma_res} pr\'esente le rapport de classification du mod\`ele g\'en\'eratif. Gemma atteint une \textbf{Accuracy de 0.632} et un \textbf{Macro-F1 de 0.630}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q4/gemma_report.png}
  \caption{Rapport de performance pour Gemma-3-4b-it (inf\'erence few-shot). Le mod\`ele pr\'esente une performance mod\'er\'ee et relativement \'equilibr\'ee, avec une confusion notable entre sentiments polaris\'es et classe neutre.}
  \label{fig:gemma_res}
\end{figure}

La matrice de confusion met en \'evidence une faiblesse : une tendance \`a classer des tweets polaris\'es (positifs/n\'egatifs) comme neutres. Ce comportement est souvent associ\'e \`a l'alignement (RLHF) des mod\`eles instruction-tuned, qui peut favoriser des sorties plus neutres en cas d'ambigu\"it\'e.

\subsubsection{R\'esultats bas\'es sur BERT}
La Fig.~\ref{fig:bert_best} pr\'esente la performance de la baseline \texttt{BERT Linear Head}. Ce mod\`ele atteint une \textbf{Accuracy de 0.664} et un \textbf{Macro-F1 de 0.666}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q4/bert_best_report.png}
  \caption{Rapport de performance pour la baseline BERT Linear Head.}
  \label{fig:bert_best}
\end{figure}

Le mod\`ele BERT pr\'esente une diagonale plus marqu\'ee dans la matrice de confusion, ce qui indique un meilleur pouvoir discriminant sur cette distribution de donn\'ees.

\subsection{Discussion : sp\'ecialisation vs g\'en\'eralisation}

La comparaison entre l'encodeur sp\'ecialis\'e (BERT) et le d\'ecodeur g\'en\'eraliste (Gemma) est r\'esum\'ee en Table~\ref{tab:llm_vs_bert}.

\begin{table}[htbp]
\caption{Comparaison directe : encodeur fine-tun\'e vs LLM few-shot}
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Mod\`ele} & \textbf{Params} & \textbf{M\'ethode} & \textbf{Macro F1} \\
\hline
\textbf{BERT (lin\'eaire)} & \textbf{110M} & \textbf{Fine-tuning} & \textbf{0.666} \\
\hline
Gemma-3-4b-it & 4B & Few-shot & 0.630 \\
\hline
\end{tabular}
\label{tab:llm_vs_bert}
\end{center}
\end{table}

\begin{enumerate}
    \item \textbf{\'Ecart de performance :} BERT surpasse Gemma d'environ \textbf{3.6\% en Macro-F1}. Cela confirme que, pour ce jeu de donn\'ees, un mod\`ele plus petit adapt\'e au domaine est plus efficace qu'un mod\`ele massif utilis\'e en few-shot.
    \item \textbf{Efficacit\'e de ressources :} l'\'ecart est important. BERT (110M) peut \^etre d\'eploy\'e avec une faible latence sur du mat\'eriel standard, tandis que Gemma (4B) requiert une VRAM significative ou une d\'ependance API.
\end{enumerate}
