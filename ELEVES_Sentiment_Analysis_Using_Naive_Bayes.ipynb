{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMQV0xV5GUQX",
        "outputId": "808358cf-d3fa-4d51-a1b6-1c70457d0df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading to /home/santiago/.cache/kagglehub/datasets/abhi8923shriv/sentiment-analysis-dataset/9.archive...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████| 54.4M/54.4M [00:02<00:00, 21.8MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download('abhi8923shriv/sentiment-analysis-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WspHhyP757H4"
      },
      "source": [
        "# Sentiment Analysis on Kaggle sentiment analysis dataset\n",
        "sentiment analysis tasks on kaggle sentiment analysis dataset using simple machine learning model: Naive bayes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgtBS7we9zxF"
      },
      "source": [
        "## Including needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:36.548968Z",
          "iopub.status.busy": "2024-09-12T08:22:36.548571Z",
          "iopub.status.idle": "2024-09-12T08:22:39.953833Z",
          "shell.execute_reply": "2024-09-12T08:22:39.952412Z",
          "shell.execute_reply.started": "2024-09-12T08:22:36.548927Z"
        },
        "id": "V56eXYTz3Wi6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --------------- MAIN LIBRARIES ------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# --------------- HELPING LIBRARIES ----------------\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ------------- Pytorch Librairies ---------------\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX8kWFB-_ou8"
      },
      "source": [
        "## Uploading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:39.957158Z",
          "iopub.status.busy": "2024-09-12T08:22:39.956494Z",
          "iopub.status.idle": "2024-09-12T08:22:39.976107Z",
          "shell.execute_reply": "2024-09-12T08:22:39.974235Z",
          "shell.execute_reply.started": "2024-09-12T08:22:39.957103Z"
        },
        "id": "K9dAjDTZBSKW",
        "outputId": "2a1964af-5ae9-4781-a91d-ffb39be37cb8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "train_dataset = path+'/train.csv'\n",
        "test_dataset = path+'/test.csv'\n",
        "\n",
        "# Check if the path exists\n",
        "print (os.path.exists(train_dataset))\n",
        "print (os.path.exists(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:39.978592Z",
          "iopub.status.busy": "2024-09-12T08:22:39.978053Z",
          "iopub.status.idle": "2024-09-12T08:22:40.231514Z",
          "shell.execute_reply": "2024-09-12T08:22:40.230228Z",
          "shell.execute_reply.started": "2024-09-12T08:22:39.978535Z"
        },
        "id": "hW9BRdvvB5-i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "train_df = pd.read_csv(train_dataset, encoding='ISO-8859-1')\n",
        "test_df = pd.read_csv(test_dataset, encoding='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.236134Z",
          "iopub.status.busy": "2024-09-12T08:22:40.234876Z",
          "iopub.status.idle": "2024-09-12T08:22:40.279444Z",
          "shell.execute_reply": "2024-09-12T08:22:40.278232Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.236076Z"
        },
        "id": "Cv2hsR9aDAkQ",
        "outputId": "d2e36aeb-3af6-413d-91a4-0e2c161d341c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "4                        Sons of ****,  negative          noon       60-70   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
              "0  Afghanistan          38928346         652860.0               60  \n",
              "1      Albania           2877797          27400.0              105  \n",
              "2      Algeria          43851044        2381740.0               18  \n",
              "3      Andorra             77265            470.0              164  \n",
              "4       Angola          32866272        1246700.0               26  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLHgZmS_KaeW"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.282164Z",
          "iopub.status.busy": "2024-09-12T08:22:40.281383Z",
          "iopub.status.idle": "2024-09-12T08:22:40.337247Z",
          "shell.execute_reply": "2024-09-12T08:22:40.335825Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.282119Z"
        },
        "id": "lQTMOPxnWhs7",
        "outputId": "5595146d-2358-4289-f2bc-c087a7e39b76",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            27481 non-null  object \n",
            " 1   text              27480 non-null  object \n",
            " 2   selected_text     27480 non-null  object \n",
            " 3   sentiment         27481 non-null  object \n",
            " 4   Time of Tweet     27481 non-null  object \n",
            " 5   Age of User       27481 non-null  object \n",
            " 6   Country           27481 non-null  object \n",
            " 7   Population -2020  27481 non-null  int64  \n",
            " 8   Land Area (Km²)   27481 non-null  float64\n",
            " 9   Density (P/Km²)   27481 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(7)\n",
            "memory usage: 2.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.340796Z",
          "iopub.status.busy": "2024-09-12T08:22:40.340393Z",
          "iopub.status.idle": "2024-09-12T08:22:40.358799Z",
          "shell.execute_reply": "2024-09-12T08:22:40.357343Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.340755Z"
        },
        "id": "GmpjaoKBWluP",
        "outputId": "2143527c-74cd-4a50-f732-82d04cd4fdb2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4815 entries, 0 to 4814\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            3534 non-null   object \n",
            " 1   text              3534 non-null   object \n",
            " 2   sentiment         3534 non-null   object \n",
            " 3   Time of Tweet     3534 non-null   object \n",
            " 4   Age of User       3534 non-null   object \n",
            " 5   Country           3534 non-null   object \n",
            " 6   Population -2020  3534 non-null   float64\n",
            " 7   Land Area (Km²)   3534 non-null   float64\n",
            " 8   Density (P/Km²)   3534 non-null   float64\n",
            "dtypes: float64(3), object(6)\n",
            "memory usage: 338.7+ KB\n"
          ]
        }
      ],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U95kjy7kKgIC"
      },
      "source": [
        "#### Handling null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.360843Z",
          "iopub.status.busy": "2024-09-12T08:22:40.360383Z",
          "iopub.status.idle": "2024-09-12T08:22:40.402343Z",
          "shell.execute_reply": "2024-09-12T08:22:40.401081Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.36079Z"
        },
        "id": "RaWIiyJWKeUd",
        "outputId": "6c61868f-1cf3-4f01-b690-d9f168cb98cc",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                1\n",
              "selected_text       1\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.404817Z",
          "iopub.status.busy": "2024-09-12T08:22:40.404388Z",
          "iopub.status.idle": "2024-09-12T08:22:40.465463Z",
          "shell.execute_reply": "2024-09-12T08:22:40.463998Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.404776Z"
        },
        "id": "_5ZDZQ73Kydz",
        "outputId": "a31675d6-563d-4ac8-be41-3b6fd77cfa95",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                0\n",
              "selected_text       0\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = train_df.dropna()\n",
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.467344Z",
          "iopub.status.busy": "2024-09-12T08:22:40.466939Z",
          "iopub.status.idle": "2024-09-12T08:22:40.481329Z",
          "shell.execute_reply": "2024-09-12T08:22:40.479919Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.4673Z"
        },
        "id": "x5nimN6_WGRR",
        "outputId": "3eee7f0a-83e3-492f-bcf0-f3edd602ab4c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              1281\n",
              "text                1281\n",
              "sentiment           1281\n",
              "Time of Tweet       1281\n",
              "Age of User         1281\n",
              "Country             1281\n",
              "Population -2020    1281\n",
              "Land Area (Km²)     1281\n",
              "Density (P/Km²)     1281\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.487599Z",
          "iopub.status.busy": "2024-09-12T08:22:40.486547Z",
          "iopub.status.idle": "2024-09-12T08:22:40.507416Z",
          "shell.execute_reply": "2024-09-12T08:22:40.506177Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.487539Z"
        },
        "id": "A3hqNN4GWP9J",
        "outputId": "d37c315f-eccb-42f3-9563-941610c401d5",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "textID              0\n",
              "text                0\n",
              "sentiment           0\n",
              "Time of Tweet       0\n",
              "Age of User         0\n",
              "Country             0\n",
              "Population -2020    0\n",
              "Land Area (Km²)     0\n",
              "Density (P/Km²)     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOgrqQewLCdw"
      },
      "source": [
        "#### Removing stopwords & lowercase all text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.509448Z",
          "iopub.status.busy": "2024-09-12T08:22:40.508972Z",
          "iopub.status.idle": "2024-09-12T08:22:40.598748Z",
          "shell.execute_reply": "2024-09-12T08:22:40.597069Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.509394Z"
        },
        "id": "Qpsxd4BWNHJO",
        "outputId": "f1abd31d-5bd5-4b9f-de18-4cb44ce81a10",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/santiago/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.601099Z",
          "iopub.status.busy": "2024-09-12T08:22:40.600609Z",
          "iopub.status.idle": "2024-09-12T08:22:40.609951Z",
          "shell.execute_reply": "2024-09-12T08:22:40.608024Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.601044Z"
        },
        "id": "GyCFZy2FOZ0u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Text preprocessing function that removes stopwords and convert text to lowercase\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:40.611901Z",
          "iopub.status.busy": "2024-09-12T08:22:40.611511Z",
          "iopub.status.idle": "2024-09-12T08:22:45.335514Z",
          "shell.execute_reply": "2024-09-12T08:22:45.334329Z",
          "shell.execute_reply.started": "2024-09-12T08:22:40.611861Z"
        },
        "id": "6Rd5y7pkOyXz",
        "outputId": "e9b5306f-5c8d-46c9-fa42-c4856f39cf98",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60</td>\n",
              "      <td>i`d responded, going</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105</td>\n",
              "      <td>sooo sad miss san diego!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18</td>\n",
              "      <td>boss bullying me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164</td>\n",
              "      <td>interview! leave alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26</td>\n",
              "      <td>sons ****, couldn`t put releases already bought</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment Time of Tweet Age of User  \\\n",
              "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
              "1                             Sooo SAD  negative          noon       21-30   \n",
              "2                          bullying me  negative         night       31-45   \n",
              "3                       leave me alone  negative       morning       46-60   \n",
              "4                        Sons of ****,  negative          noon       60-70   \n",
              "\n",
              "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \\\n",
              "0  Afghanistan          38928346         652860.0               60   \n",
              "1      Albania           2877797          27400.0              105   \n",
              "2      Algeria          43851044        2381740.0               18   \n",
              "3      Andorra             77265            470.0              164   \n",
              "4       Angola          32866272        1246700.0               26   \n",
              "\n",
              "                                    processed_text  \n",
              "0                             i`d responded, going  \n",
              "1                       sooo sad miss san diego!!!  \n",
              "2                              boss bullying me...  \n",
              "3                           interview! leave alone  \n",
              "4  sons ****, couldn`t put releases already bought  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply preprocessing on train dataset\n",
        "train_df['processed_text'] = train_df['text'].apply(preprocess_text)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:22:45.337762Z",
          "iopub.status.busy": "2024-09-12T08:22:45.337232Z",
          "iopub.status.idle": "2024-09-12T08:22:45.959644Z",
          "shell.execute_reply": "2024-09-12T08:22:45.958512Z",
          "shell.execute_reply.started": "2024-09-12T08:22:45.337709Z"
        },
        "id": "2Vpcp2FVXXVQ",
        "outputId": "c6770cf5-f897-410a-b6ae-7df5bd9181a2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>Time of Tweet</th>\n",
              "      <th>Age of User</th>\n",
              "      <th>Country</th>\n",
              "      <th>Population -2020</th>\n",
              "      <th>Land Area (Km²)</th>\n",
              "      <th>Density (P/Km²)</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "      <td>neutral</td>\n",
              "      <td>morning</td>\n",
              "      <td>0-20</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>38928346.0</td>\n",
              "      <td>652860.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>last session day http://twitpic.com/67ezh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>Shanghai is also really exciting (precisely -...</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>21-30</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2877797.0</td>\n",
              "      <td>27400.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>shanghai also really exciting (precisely -- sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "      <td>negative</td>\n",
              "      <td>night</td>\n",
              "      <td>31-45</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>43851044.0</td>\n",
              "      <td>2381740.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>recession hit veronique branquinho, quit compa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01082688c6</td>\n",
              "      <td>happy bday!</td>\n",
              "      <td>positive</td>\n",
              "      <td>morning</td>\n",
              "      <td>46-60</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>77265.0</td>\n",
              "      <td>470.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>happy bday!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "      <td>positive</td>\n",
              "      <td>noon</td>\n",
              "      <td>60-70</td>\n",
              "      <td>Angola</td>\n",
              "      <td>32866272.0</td>\n",
              "      <td>1246700.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>http://twitpic.com/4w75p - like it!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID                                               text sentiment  \\\n",
              "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
              "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
              "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
              "3  01082688c6                                        happy bday!  positive   \n",
              "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
              "\n",
              "  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n",
              "0       morning        0-20  Afghanistan        38928346.0         652860.0   \n",
              "1          noon       21-30      Albania         2877797.0          27400.0   \n",
              "2         night       31-45      Algeria        43851044.0        2381740.0   \n",
              "3       morning       46-60      Andorra           77265.0            470.0   \n",
              "4          noon       60-70       Angola        32866272.0        1246700.0   \n",
              "\n",
              "   Density (P/Km²)                                     processed_text  \n",
              "0             60.0          last session day http://twitpic.com/67ezh  \n",
              "1            105.0  shanghai also really exciting (precisely -- sk...  \n",
              "2             18.0  recession hit veronique branquinho, quit compa...  \n",
              "3            164.0                                        happy bday!  \n",
              "4             26.0               http://twitpic.com/4w75p - like it!!  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply preprocessing on test dataset\n",
        "test_df['processed_text'] = test_df['text'].apply(preprocess_text)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9FZF-S6RwT0"
      },
      "source": [
        "## Check Imbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:27:19.351826Z",
          "iopub.status.busy": "2024-09-12T08:27:19.351335Z",
          "iopub.status.idle": "2024-09-12T08:27:19.610508Z",
          "shell.execute_reply": "2024-09-12T08:27:19.609354Z",
          "shell.execute_reply.started": "2024-09-12T08:27:19.351775Z"
        },
        "id": "uRP-7dXHUcgb",
        "outputId": "c55e8422-deb7-49b4-b029-1d1d3a550c50",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Distribution of sentiment labels\n",
        "sns.countplot(x='sentiment', data=train_df)\n",
        "plt.title(\"Distribution of Sentiment Labels\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Transform sentiment into 3 classes\n",
        "# Example mapping: positive -> 2, neutral -> 1, negative -> 0\n",
        "sentiment_mapping = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
        "train_df[\"sentiment_class\"] = train_df[\"sentiment\"].map(sentiment_mapping)\n",
        "test_df[\"sentiment_class\"] = test_df[\"sentiment\"].map(sentiment_mapping)\n",
        "train_df.to_csv(\"train_df_processed.csv\", index=False)\n",
        "test_df.to_csv(\"test_df_processed.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppFEsZZXIW75"
      },
      "outputs": [],
      "source": [
        "# 2. Extract all the values from the 'processed_text' column into a list\n",
        "trainval_x = train_df[\"processed_text\"].tolist()\n",
        "trainval_y = train_df[\"sentiment_class\"].tolist()\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(trainval_x, trainval_y, test_size=0.25, random_state=42)\n",
        "\n",
        "test_x = test_df[\"processed_text\"].tolist()\n",
        "test_y = test_df[\"sentiment_class\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGje1w01rjlw",
        "outputId": "862fa31c-ba1a-4f4d-ce50-676b87f2b2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27480 6870 3534\n"
          ]
        }
      ],
      "source": [
        "print(len(trainval_x),len(val_x),len(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meidY0NVsChh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "PRETRAINED_MODEL = \"bert-base-uncased\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Custom Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Extract embeddings for all data\n",
        "def extract_embeddings(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Extracts embeddings for all data using a pre-trained BERT model.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.BertModel): Pre-trained BERT model.\n",
        "        dataloader (DataLoader): DataLoader for the dataset.\n",
        "        device (torch.device): Device to run the model on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A matrix of size (number_of_samples, embedding_size).\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    embeddings = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # Forward pass through BERT\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            pooled_output = outputs.pooler_output  # CLS token representation\n",
        "\n",
        "            # Append embeddings to the list\n",
        "            embeddings.append(pooled_output.cpu())\n",
        "\n",
        "    # Combine all embeddings into a single matrix\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "# Initialize tokenizer, dataset, and dataloader\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
        "traindataset = TextDataset(train_x, train_y, tokenizer, MAX_LENGTH)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "valdataset = TextDataset(val_x, val_y, tokenizer, MAX_LENGTH)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "train_embeddings = extract_embeddings(bert, trainloader, device)\n",
        "train_embeddings =train_embeddings.cpu()\n",
        "\n",
        "val_embeddings = extract_embeddings(bert, valloader, device)\n",
        "val_embeddings =val_embeddings.cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWzk4bUcvX03",
        "outputId": "a905e572-cd4f-4db6-9117-16f9e062d890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20610, 768])\n",
            "torch.Size([6870, 768])\n"
          ]
        }
      ],
      "source": [
        "print(train_embeddings.size())\n",
        "print(val_embeddings.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHR_N9OiwgYL"
      },
      "outputs": [],
      "source": [
        "criterion= nn.CrossEntropyLoss()\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "# Custom Dataset\n",
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        embeddings = self.embeddings[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": embeddings.squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Model Definition\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "\n",
        "        # Fully connected layer for classification\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "\n",
        "        # Pass through the fully connected layer\n",
        "        logits = self.fc(input_ids)\n",
        "        return logits\n",
        "\n",
        "# training script\n",
        "\n",
        "def train( model, train_loader, optimizer, epoch,log_interval=50):\n",
        "    model.train()\n",
        "    loss_cpu=0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, target = data['input_ids'],data['label']\n",
        "        inputs, target = inputs.cuda(), target.cuda()\n",
        "        inputs =inputs.detach()\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        loss_cpu+= loss.item()\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, EPOCHS, batch_idx+1,\n",
        "                    (len(train_loader)//BATCH_SIZE)+1, loss.item(), 100.*correct/total))\n",
        "            #n_iter=epoch * len(train_loader) + batch_idx\n",
        "\n",
        "    return loss_cpu/len(train_loader)\n",
        "\n",
        "# testing script\n",
        "def test( model, test_loader,epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss_MSE =0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(test_loader, 0):\n",
        "            inputs, target = data['input_ids'],data['label']\n",
        "            inputs, target = inputs.cuda(), target.cuda()\n",
        "            outputs  = model(inputs)\n",
        "            loss = criterion(outputs,target)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target.data).cpu().sum()\n",
        "            test_loss_MSE+= loss.item()\n",
        "\n",
        "    test_loss_MSE = test_loss_MSE/ len(test_loader)\n",
        "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), 100.*correct/total))\n",
        "    return test_loss_MSE, 100.*correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0X6VeclzYro",
        "outputId": "1d64bacd-dc0d-42b0-a915-387380137513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let us Train.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3/ training model 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "| Epoch [  0/ 50] Iter[  1/  6]\t\tLoss: 1.0910 Acc@1: 40.625%\n",
            "| Epoch [  0/ 50] Iter[ 51/  6]\t\tLoss: 1.0971 Acc@1: 40.012%\n",
            "| Epoch [  0/ 50] Iter[101/  6]\t\tLoss: 1.0606 Acc@1: 40.671%\n",
            "| Epoch [  0/ 50] Iter[151/  6]\t\tLoss: 1.0552 Acc@1: 41.505%\n",
            "| Epoch [  0/ 50] Iter[201/  6]\t\tLoss: 1.0201 Acc@1: 42.607%\n",
            "| Epoch [  0/ 50] Iter[251/  6]\t\tLoss: 0.9993 Acc@1: 43.762%\n",
            "| Epoch [  0/ 50] Iter[301/  6]\t\tLoss: 0.9892 Acc@1: 44.451%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 1.0242 Acc@1: 51.72%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 1.0183745716457013 for epoch : 0 ERROR TEST =  1.0183745716457013\n",
            "| Epoch [  1/ 50] Iter[  1/  6]\t\tLoss: 1.0173 Acc@1: 50.000%\n",
            "| Epoch [  1/ 50] Iter[ 51/  6]\t\tLoss: 0.9601 Acc@1: 50.245%\n",
            "| Epoch [  1/ 50] Iter[101/  6]\t\tLoss: 0.9958 Acc@1: 50.588%\n",
            "| Epoch [  1/ 50] Iter[151/  6]\t\tLoss: 1.0419 Acc@1: 51.366%\n",
            "| Epoch [  1/ 50] Iter[201/  6]\t\tLoss: 0.9603 Acc@1: 51.625%\n",
            "| Epoch [  1/ 50] Iter[251/  6]\t\tLoss: 0.9204 Acc@1: 52.160%\n",
            "| Epoch [  1/ 50] Iter[301/  6]\t\tLoss: 0.9968 Acc@1: 52.492%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 0.8862 Acc@1: 53.25%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.9585773983487377 for epoch : 1 ERROR TEST =  0.9585773983487377\n",
            "| Epoch [  2/ 50] Iter[  1/  6]\t\tLoss: 0.8937 Acc@1: 64.062%\n",
            "| Epoch [  2/ 50] Iter[ 51/  6]\t\tLoss: 0.9257 Acc@1: 53.309%\n",
            "| Epoch [  2/ 50] Iter[101/  6]\t\tLoss: 0.8809 Acc@1: 53.280%\n",
            "| Epoch [  2/ 50] Iter[151/  6]\t\tLoss: 0.9927 Acc@1: 53.353%\n",
            "| Epoch [  2/ 50] Iter[201/  6]\t\tLoss: 0.9282 Acc@1: 54.299%\n",
            "| Epoch [  2/ 50] Iter[251/  6]\t\tLoss: 0.9392 Acc@1: 54.407%\n",
            "| Epoch [  2/ 50] Iter[301/  6]\t\tLoss: 0.9487 Acc@1: 54.625%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 0.9937 Acc@1: 54.69%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.9570597619922073 for epoch : 2 ERROR TEST =  0.9570597619922073\n",
            "| Epoch [  3/ 50] Iter[  1/  6]\t\tLoss: 0.9507 Acc@1: 56.250%\n",
            "| Epoch [  3/ 50] Iter[ 51/  6]\t\tLoss: 0.9554 Acc@1: 55.852%\n",
            "| Epoch [  3/ 50] Iter[101/  6]\t\tLoss: 0.9014 Acc@1: 56.188%\n",
            "| Epoch [  3/ 50] Iter[151/  6]\t\tLoss: 0.8779 Acc@1: 55.940%\n",
            "| Epoch [  3/ 50] Iter[201/  6]\t\tLoss: 0.9799 Acc@1: 55.683%\n",
            "| Epoch [  3/ 50] Iter[251/  6]\t\tLoss: 0.8364 Acc@1: 56.256%\n",
            "| Epoch [  3/ 50] Iter[301/  6]\t\tLoss: 0.8823 Acc@1: 56.328%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 1.0489 Acc@1: 57.19%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.9340858222157867 for epoch : 3 ERROR TEST =  0.9340858222157867\n",
            "| Epoch [  4/ 50] Iter[  1/  6]\t\tLoss: 0.9266 Acc@1: 57.812%\n",
            "| Epoch [  4/ 50] Iter[ 51/  6]\t\tLoss: 0.8598 Acc@1: 56.495%\n",
            "| Epoch [  4/ 50] Iter[101/  6]\t\tLoss: 0.9334 Acc@1: 56.699%\n",
            "| Epoch [  4/ 50] Iter[151/  6]\t\tLoss: 0.9561 Acc@1: 57.388%\n",
            "| Epoch [  4/ 50] Iter[201/  6]\t\tLoss: 0.8811 Acc@1: 57.113%\n",
            "| Epoch [  4/ 50] Iter[251/  6]\t\tLoss: 0.9589 Acc@1: 57.234%\n",
            "| Epoch [  4/ 50] Iter[301/  6]\t\tLoss: 0.9565 Acc@1: 57.371%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 0.8888 Acc@1: 57.98%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.9062874146081783 for epoch : 4 ERROR TEST =  0.9062874146081783\n",
            "| Epoch [  5/ 50] Iter[  1/  6]\t\tLoss: 0.9257 Acc@1: 53.125%\n",
            "| Epoch [  5/ 50] Iter[ 51/  6]\t\tLoss: 0.8724 Acc@1: 56.863%\n",
            "| Epoch [  5/ 50] Iter[101/  6]\t\tLoss: 0.8374 Acc@1: 57.673%\n",
            "| Epoch [  5/ 50] Iter[151/  6]\t\tLoss: 0.9877 Acc@1: 58.144%\n",
            "| Epoch [  5/ 50] Iter[201/  6]\t\tLoss: 1.0269 Acc@1: 58.100%\n",
            "| Epoch [  5/ 50] Iter[251/  6]\t\tLoss: 0.8790 Acc@1: 58.024%\n",
            "| Epoch [  5/ 50] Iter[301/  6]\t\tLoss: 0.8489 Acc@1: 58.036%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 0.9642 Acc@1: 57.29%\n",
            "lr = 0.001\n",
            "| Epoch [  6/ 50] Iter[  1/  6]\t\tLoss: 0.8486 Acc@1: 62.500%\n",
            "| Epoch [  6/ 50] Iter[ 51/  6]\t\tLoss: 0.8409 Acc@1: 59.651%\n",
            "| Epoch [  6/ 50] Iter[101/  6]\t\tLoss: 0.8254 Acc@1: 58.911%\n",
            "| Epoch [  6/ 50] Iter[151/  6]\t\tLoss: 0.8917 Acc@1: 58.858%\n",
            "| Epoch [  6/ 50] Iter[201/  6]\t\tLoss: 0.8625 Acc@1: 58.823%\n",
            "| Epoch [  6/ 50] Iter[251/  6]\t\tLoss: 0.8390 Acc@1: 58.678%\n",
            "| Epoch [  6/ 50] Iter[301/  6]\t\tLoss: 1.0646 Acc@1: 58.705%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 0.9465 Acc@1: 58.17%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.9013462480571535 for epoch : 6 ERROR TEST =  0.9013462480571535\n",
            "| Epoch [  7/ 50] Iter[  1/  6]\t\tLoss: 0.7995 Acc@1: 60.938%\n",
            "| Epoch [  7/ 50] Iter[ 51/  6]\t\tLoss: 0.8973 Acc@1: 57.996%\n",
            "| Epoch [  7/ 50] Iter[101/  6]\t\tLoss: 0.8400 Acc@1: 58.462%\n",
            "| Epoch [  7/ 50] Iter[151/  6]\t\tLoss: 0.9819 Acc@1: 58.827%\n",
            "| Epoch [  7/ 50] Iter[201/  6]\t\tLoss: 0.8524 Acc@1: 58.683%\n",
            "| Epoch [  7/ 50] Iter[251/  6]\t\tLoss: 0.9848 Acc@1: 58.790%\n",
            "| Epoch [  7/ 50] Iter[301/  6]\t\tLoss: 0.8529 Acc@1: 58.892%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 0.7417 Acc@1: 57.86%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8915062165922589 for epoch : 7 ERROR TEST =  0.8915062165922589\n",
            "| Epoch [  8/ 50] Iter[  1/  6]\t\tLoss: 0.9198 Acc@1: 56.250%\n",
            "| Epoch [  8/ 50] Iter[ 51/  6]\t\tLoss: 0.8822 Acc@1: 58.793%\n",
            "| Epoch [  8/ 50] Iter[101/  6]\t\tLoss: 0.8183 Acc@1: 59.483%\n",
            "| Epoch [  8/ 50] Iter[151/  6]\t\tLoss: 0.9013 Acc@1: 59.685%\n",
            "| Epoch [  8/ 50] Iter[201/  6]\t\tLoss: 0.8780 Acc@1: 59.803%\n",
            "| Epoch [  8/ 50] Iter[251/  6]\t\tLoss: 0.7285 Acc@1: 59.823%\n",
            "| Epoch [  8/ 50] Iter[301/  6]\t\tLoss: 0.8611 Acc@1: 59.868%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 0.8032 Acc@1: 56.94%\n",
            "lr = 0.001\n",
            "| Epoch [  9/ 50] Iter[  1/  6]\t\tLoss: 0.8554 Acc@1: 59.375%\n",
            "| Epoch [  9/ 50] Iter[ 51/  6]\t\tLoss: 0.9321 Acc@1: 59.559%\n",
            "| Epoch [  9/ 50] Iter[101/  6]\t\tLoss: 0.7922 Acc@1: 60.118%\n",
            "| Epoch [  9/ 50] Iter[151/  6]\t\tLoss: 0.7984 Acc@1: 60.037%\n",
            "| Epoch [  9/ 50] Iter[201/  6]\t\tLoss: 0.9074 Acc@1: 60.393%\n",
            "| Epoch [  9/ 50] Iter[251/  6]\t\tLoss: 1.0491 Acc@1: 60.321%\n",
            "| Epoch [  9/ 50] Iter[301/  6]\t\tLoss: 0.7916 Acc@1: 60.071%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 0.9221 Acc@1: 59.37%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8785450762068784 for epoch : 9 ERROR TEST =  0.8785450762068784\n",
            "| Epoch [ 10/ 50] Iter[  1/  6]\t\tLoss: 0.9419 Acc@1: 56.250%\n",
            "| Epoch [ 10/ 50] Iter[ 51/  6]\t\tLoss: 0.8269 Acc@1: 60.325%\n",
            "| Epoch [ 10/ 50] Iter[101/  6]\t\tLoss: 0.7987 Acc@1: 59.452%\n",
            "| Epoch [ 10/ 50] Iter[151/  6]\t\tLoss: 0.8485 Acc@1: 59.696%\n",
            "| Epoch [ 10/ 50] Iter[201/  6]\t\tLoss: 0.8624 Acc@1: 59.927%\n",
            "| Epoch [ 10/ 50] Iter[251/  6]\t\tLoss: 0.8551 Acc@1: 59.836%\n",
            "| Epoch [ 10/ 50] Iter[301/  6]\t\tLoss: 0.8006 Acc@1: 59.941%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 0.7725 Acc@1: 57.03%\n",
            "lr = 0.001\n",
            "| Epoch [ 11/ 50] Iter[  1/  6]\t\tLoss: 0.8618 Acc@1: 57.812%\n",
            "| Epoch [ 11/ 50] Iter[ 51/  6]\t\tLoss: 0.8447 Acc@1: 60.723%\n",
            "| Epoch [ 11/ 50] Iter[101/  6]\t\tLoss: 0.7660 Acc@1: 61.340%\n",
            "| Epoch [ 11/ 50] Iter[151/  6]\t\tLoss: 0.8818 Acc@1: 60.317%\n",
            "| Epoch [ 11/ 50] Iter[201/  6]\t\tLoss: 0.8772 Acc@1: 60.424%\n",
            "| Epoch [ 11/ 50] Iter[251/  6]\t\tLoss: 0.8744 Acc@1: 60.738%\n",
            "| Epoch [ 11/ 50] Iter[301/  6]\t\tLoss: 0.7012 Acc@1: 60.673%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 0.9250 Acc@1: 59.58%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8778273468768155 for epoch : 11 ERROR TEST =  0.8778273468768155\n",
            "| Epoch [ 12/ 50] Iter[  1/  6]\t\tLoss: 0.8405 Acc@1: 62.500%\n",
            "| Epoch [ 12/ 50] Iter[ 51/  6]\t\tLoss: 0.9229 Acc@1: 59.620%\n",
            "| Epoch [ 12/ 50] Iter[101/  6]\t\tLoss: 0.9390 Acc@1: 58.926%\n",
            "| Epoch [ 12/ 50] Iter[151/  6]\t\tLoss: 0.9350 Acc@1: 59.240%\n",
            "| Epoch [ 12/ 50] Iter[201/  6]\t\tLoss: 0.8650 Acc@1: 59.764%\n",
            "| Epoch [ 12/ 50] Iter[251/  6]\t\tLoss: 0.9058 Acc@1: 59.966%\n",
            "| Epoch [ 12/ 50] Iter[301/  6]\t\tLoss: 0.7847 Acc@1: 59.936%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 0.6599 Acc@1: 58.53%\n",
            "lr = 0.001\n",
            "| Epoch [ 13/ 50] Iter[  1/  6]\t\tLoss: 0.8183 Acc@1: 59.375%\n",
            "| Epoch [ 13/ 50] Iter[ 51/  6]\t\tLoss: 0.7650 Acc@1: 61.366%\n",
            "| Epoch [ 13/ 50] Iter[101/  6]\t\tLoss: 0.8188 Acc@1: 61.185%\n",
            "| Epoch [ 13/ 50] Iter[151/  6]\t\tLoss: 0.8079 Acc@1: 61.010%\n",
            "| Epoch [ 13/ 50] Iter[201/  6]\t\tLoss: 0.7889 Acc@1: 60.813%\n",
            "| Epoch [ 13/ 50] Iter[251/  6]\t\tLoss: 0.8715 Acc@1: 60.919%\n",
            "| Epoch [ 13/ 50] Iter[301/  6]\t\tLoss: 0.8171 Acc@1: 60.745%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 0.8342 Acc@1: 60.04%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8713359843801569 for epoch : 13 ERROR TEST =  0.8713359843801569\n",
            "| Epoch [ 14/ 50] Iter[  1/  6]\t\tLoss: 0.7663 Acc@1: 65.625%\n",
            "| Epoch [ 14/ 50] Iter[ 51/  6]\t\tLoss: 0.8977 Acc@1: 58.915%\n",
            "| Epoch [ 14/ 50] Iter[101/  6]\t\tLoss: 0.8598 Acc@1: 59.468%\n",
            "| Epoch [ 14/ 50] Iter[151/  6]\t\tLoss: 0.7679 Acc@1: 60.089%\n",
            "| Epoch [ 14/ 50] Iter[201/  6]\t\tLoss: 0.8245 Acc@1: 60.246%\n",
            "| Epoch [ 14/ 50] Iter[251/  6]\t\tLoss: 0.8052 Acc@1: 60.682%\n",
            "| Epoch [ 14/ 50] Iter[301/  6]\t\tLoss: 0.8523 Acc@1: 60.678%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 0.8714 Acc@1: 56.64%\n",
            "lr = 0.001\n",
            "| Epoch [ 15/ 50] Iter[  1/  6]\t\tLoss: 0.8721 Acc@1: 60.938%\n",
            "| Epoch [ 15/ 50] Iter[ 51/  6]\t\tLoss: 0.9980 Acc@1: 59.344%\n",
            "| Epoch [ 15/ 50] Iter[101/  6]\t\tLoss: 0.9353 Acc@1: 59.746%\n",
            "| Epoch [ 15/ 50] Iter[151/  6]\t\tLoss: 0.8850 Acc@1: 59.934%\n",
            "| Epoch [ 15/ 50] Iter[201/  6]\t\tLoss: 0.8309 Acc@1: 60.082%\n",
            "| Epoch [ 15/ 50] Iter[251/  6]\t\tLoss: 0.8584 Acc@1: 60.552%\n",
            "| Epoch [ 15/ 50] Iter[301/  6]\t\tLoss: 0.9375 Acc@1: 60.787%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 0.9030 Acc@1: 59.71%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8707294624160837 for epoch : 15 ERROR TEST =  0.8707294624160837\n",
            "| Epoch [ 16/ 50] Iter[  1/  6]\t\tLoss: 0.8072 Acc@1: 62.500%\n",
            "| Epoch [ 16/ 50] Iter[ 51/  6]\t\tLoss: 0.8661 Acc@1: 59.957%\n",
            "| Epoch [ 16/ 50] Iter[101/  6]\t\tLoss: 0.7876 Acc@1: 60.798%\n",
            "| Epoch [ 16/ 50] Iter[151/  6]\t\tLoss: 0.9865 Acc@1: 60.637%\n",
            "| Epoch [ 16/ 50] Iter[201/  6]\t\tLoss: 0.8798 Acc@1: 60.619%\n",
            "| Epoch [ 16/ 50] Iter[251/  6]\t\tLoss: 0.8934 Acc@1: 61.031%\n",
            "| Epoch [ 16/ 50] Iter[301/  6]\t\tLoss: 0.8506 Acc@1: 61.150%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 0.8877 Acc@1: 60.09%\n",
            "lr = 0.001\n",
            "| Epoch [ 17/ 50] Iter[  1/  6]\t\tLoss: 0.8672 Acc@1: 64.062%\n",
            "| Epoch [ 17/ 50] Iter[ 51/  6]\t\tLoss: 0.8002 Acc@1: 62.163%\n",
            "| Epoch [ 17/ 50] Iter[101/  6]\t\tLoss: 0.8980 Acc@1: 60.365%\n",
            "| Epoch [ 17/ 50] Iter[151/  6]\t\tLoss: 0.8588 Acc@1: 60.430%\n",
            "| Epoch [ 17/ 50] Iter[201/  6]\t\tLoss: 0.9858 Acc@1: 60.354%\n",
            "| Epoch [ 17/ 50] Iter[251/  6]\t\tLoss: 0.9197 Acc@1: 60.483%\n",
            "| Epoch [ 17/ 50] Iter[301/  6]\t\tLoss: 0.8276 Acc@1: 60.647%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 0.8080 Acc@1: 59.46%\n",
            "lr = 0.001\n",
            "| Epoch [ 18/ 50] Iter[  1/  6]\t\tLoss: 0.8369 Acc@1: 60.938%\n",
            "| Epoch [ 18/ 50] Iter[ 51/  6]\t\tLoss: 0.7882 Acc@1: 61.152%\n",
            "| Epoch [ 18/ 50] Iter[101/  6]\t\tLoss: 0.8810 Acc@1: 61.711%\n",
            "| Epoch [ 18/ 50] Iter[151/  6]\t\tLoss: 0.8367 Acc@1: 61.527%\n",
            "| Epoch [ 18/ 50] Iter[201/  6]\t\tLoss: 0.8269 Acc@1: 61.427%\n",
            "| Epoch [ 18/ 50] Iter[251/  6]\t\tLoss: 0.8637 Acc@1: 61.299%\n",
            "| Epoch [ 18/ 50] Iter[301/  6]\t\tLoss: 0.9075 Acc@1: 61.540%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 0.9124 Acc@1: 58.08%\n",
            "lr = 0.001\n",
            "| Epoch [ 19/ 50] Iter[  1/  6]\t\tLoss: 0.9012 Acc@1: 57.812%\n",
            "| Epoch [ 19/ 50] Iter[ 51/  6]\t\tLoss: 0.8268 Acc@1: 62.286%\n",
            "| Epoch [ 19/ 50] Iter[101/  6]\t\tLoss: 0.7210 Acc@1: 60.582%\n",
            "| Epoch [ 19/ 50] Iter[151/  6]\t\tLoss: 0.8346 Acc@1: 60.896%\n",
            "| Epoch [ 19/ 50] Iter[201/  6]\t\tLoss: 0.8713 Acc@1: 60.906%\n",
            "| Epoch [ 19/ 50] Iter[251/  6]\t\tLoss: 0.8477 Acc@1: 60.975%\n",
            "| Epoch [ 19/ 50] Iter[301/  6]\t\tLoss: 0.8428 Acc@1: 61.057%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 0.8768 Acc@1: 59.53%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8666796971250463 for epoch : 19 ERROR TEST =  0.8666796971250463\n",
            "| Epoch [ 20/ 50] Iter[  1/  6]\t\tLoss: 0.8109 Acc@1: 60.938%\n",
            "| Epoch [ 20/ 50] Iter[ 51/  6]\t\tLoss: 0.8601 Acc@1: 62.040%\n",
            "| Epoch [ 20/ 50] Iter[101/  6]\t\tLoss: 0.7861 Acc@1: 61.618%\n",
            "| Epoch [ 20/ 50] Iter[151/  6]\t\tLoss: 0.9587 Acc@1: 61.393%\n",
            "| Epoch [ 20/ 50] Iter[201/  6]\t\tLoss: 0.8578 Acc@1: 61.124%\n",
            "| Epoch [ 20/ 50] Iter[251/  6]\t\tLoss: 0.8326 Acc@1: 60.925%\n",
            "| Epoch [ 20/ 50] Iter[301/  6]\t\tLoss: 0.8264 Acc@1: 61.135%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 0.6821 Acc@1: 60.32%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8613337493605084 for epoch : 20 ERROR TEST =  0.8613337493605084\n",
            "| Epoch [ 21/ 50] Iter[  1/  6]\t\tLoss: 0.9035 Acc@1: 59.375%\n",
            "| Epoch [ 21/ 50] Iter[ 51/  6]\t\tLoss: 0.7894 Acc@1: 61.642%\n",
            "| Epoch [ 21/ 50] Iter[101/  6]\t\tLoss: 0.8835 Acc@1: 60.922%\n",
            "| Epoch [ 21/ 50] Iter[151/  6]\t\tLoss: 0.9177 Acc@1: 61.144%\n",
            "| Epoch [ 21/ 50] Iter[201/  6]\t\tLoss: 0.7961 Acc@1: 61.404%\n",
            "| Epoch [ 21/ 50] Iter[251/  6]\t\tLoss: 0.8799 Acc@1: 61.572%\n",
            "| Epoch [ 21/ 50] Iter[301/  6]\t\tLoss: 0.8879 Acc@1: 61.571%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 1.2433 Acc@1: 61.31%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8595685765699104 for epoch : 21 ERROR TEST =  0.8595685765699104\n",
            "| Epoch [ 22/ 50] Iter[  1/  6]\t\tLoss: 0.6953 Acc@1: 76.562%\n",
            "| Epoch [ 22/ 50] Iter[ 51/  6]\t\tLoss: 0.8884 Acc@1: 62.806%\n",
            "| Epoch [ 22/ 50] Iter[101/  6]\t\tLoss: 0.8156 Acc@1: 62.423%\n",
            "| Epoch [ 22/ 50] Iter[151/  6]\t\tLoss: 0.8559 Acc@1: 61.745%\n",
            "| Epoch [ 22/ 50] Iter[201/  6]\t\tLoss: 0.8101 Acc@1: 61.692%\n",
            "| Epoch [ 22/ 50] Iter[251/  6]\t\tLoss: 0.7847 Acc@1: 61.572%\n",
            "| Epoch [ 22/ 50] Iter[301/  6]\t\tLoss: 0.8611 Acc@1: 61.555%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 0.9121 Acc@1: 61.06%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8579122528985694 for epoch : 22 ERROR TEST =  0.8579122528985694\n",
            "| Epoch [ 23/ 50] Iter[  1/  6]\t\tLoss: 0.8807 Acc@1: 53.125%\n",
            "| Epoch [ 23/ 50] Iter[ 51/  6]\t\tLoss: 0.7724 Acc@1: 62.776%\n",
            "| Epoch [ 23/ 50] Iter[101/  6]\t\tLoss: 0.9417 Acc@1: 62.438%\n",
            "| Epoch [ 23/ 50] Iter[151/  6]\t\tLoss: 0.8944 Acc@1: 62.531%\n",
            "| Epoch [ 23/ 50] Iter[201/  6]\t\tLoss: 0.9190 Acc@1: 62.205%\n",
            "| Epoch [ 23/ 50] Iter[251/  6]\t\tLoss: 0.9377 Acc@1: 62.108%\n",
            "| Epoch [ 23/ 50] Iter[301/  6]\t\tLoss: 0.8340 Acc@1: 61.960%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 0.9621 Acc@1: 60.61%\n",
            "lr = 0.001\n",
            "| Epoch [ 24/ 50] Iter[  1/  6]\t\tLoss: 0.8664 Acc@1: 62.500%\n",
            "| Epoch [ 24/ 50] Iter[ 51/  6]\t\tLoss: 0.7779 Acc@1: 60.723%\n",
            "| Epoch [ 24/ 50] Iter[101/  6]\t\tLoss: 0.8444 Acc@1: 61.077%\n",
            "| Epoch [ 24/ 50] Iter[151/  6]\t\tLoss: 0.8290 Acc@1: 61.186%\n",
            "| Epoch [ 24/ 50] Iter[201/  6]\t\tLoss: 0.8547 Acc@1: 61.396%\n",
            "| Epoch [ 24/ 50] Iter[251/  6]\t\tLoss: 0.8975 Acc@1: 61.485%\n",
            "| Epoch [ 24/ 50] Iter[301/  6]\t\tLoss: 0.8319 Acc@1: 61.602%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 0.8876 Acc@1: 60.19%\n",
            "lr = 0.001\n",
            "| Epoch [ 25/ 50] Iter[  1/  6]\t\tLoss: 0.8748 Acc@1: 59.375%\n",
            "| Epoch [ 25/ 50] Iter[ 51/  6]\t\tLoss: 0.8160 Acc@1: 61.550%\n",
            "| Epoch [ 25/ 50] Iter[101/  6]\t\tLoss: 0.7702 Acc@1: 61.603%\n",
            "| Epoch [ 25/ 50] Iter[151/  6]\t\tLoss: 0.7370 Acc@1: 61.827%\n",
            "| Epoch [ 25/ 50] Iter[201/  6]\t\tLoss: 0.7623 Acc@1: 61.964%\n",
            "| Epoch [ 25/ 50] Iter[251/  6]\t\tLoss: 0.9337 Acc@1: 62.282%\n",
            "| Epoch [ 25/ 50] Iter[301/  6]\t\tLoss: 0.8670 Acc@1: 62.121%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 1.0666 Acc@1: 59.20%\n",
            "lr = 0.001\n",
            "| Epoch [ 26/ 50] Iter[  1/  6]\t\tLoss: 0.8693 Acc@1: 65.625%\n",
            "| Epoch [ 26/ 50] Iter[ 51/  6]\t\tLoss: 0.8223 Acc@1: 61.489%\n",
            "| Epoch [ 26/ 50] Iter[101/  6]\t\tLoss: 0.8024 Acc@1: 61.216%\n",
            "| Epoch [ 26/ 50] Iter[151/  6]\t\tLoss: 0.7645 Acc@1: 61.734%\n",
            "| Epoch [ 26/ 50] Iter[201/  6]\t\tLoss: 0.7885 Acc@1: 61.614%\n",
            "| Epoch [ 26/ 50] Iter[251/  6]\t\tLoss: 0.8161 Acc@1: 61.467%\n",
            "| Epoch [ 26/ 50] Iter[301/  6]\t\tLoss: 0.9084 Acc@1: 61.529%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 0.5973 Acc@1: 61.11%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8534559370191009 for epoch : 26 ERROR TEST =  0.8534559370191009\n",
            "| Epoch [ 27/ 50] Iter[  1/  6]\t\tLoss: 0.8139 Acc@1: 67.188%\n",
            "| Epoch [ 27/ 50] Iter[ 51/  6]\t\tLoss: 1.0259 Acc@1: 60.723%\n",
            "| Epoch [ 27/ 50] Iter[101/  6]\t\tLoss: 0.7244 Acc@1: 61.139%\n",
            "| Epoch [ 27/ 50] Iter[151/  6]\t\tLoss: 0.7579 Acc@1: 61.362%\n",
            "| Epoch [ 27/ 50] Iter[201/  6]\t\tLoss: 0.8916 Acc@1: 61.816%\n",
            "| Epoch [ 27/ 50] Iter[251/  6]\t\tLoss: 0.8387 Acc@1: 61.990%\n",
            "| Epoch [ 27/ 50] Iter[301/  6]\t\tLoss: 0.9621 Acc@1: 61.825%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 0.9312 Acc@1: 58.24%\n",
            "lr = 0.001\n",
            "| Epoch [ 28/ 50] Iter[  1/  6]\t\tLoss: 0.8835 Acc@1: 56.250%\n",
            "| Epoch [ 28/ 50] Iter[ 51/  6]\t\tLoss: 0.8074 Acc@1: 60.355%\n",
            "| Epoch [ 28/ 50] Iter[101/  6]\t\tLoss: 0.8768 Acc@1: 61.742%\n",
            "| Epoch [ 28/ 50] Iter[151/  6]\t\tLoss: 0.8367 Acc@1: 61.527%\n",
            "| Epoch [ 28/ 50] Iter[201/  6]\t\tLoss: 0.7639 Acc@1: 61.381%\n",
            "| Epoch [ 28/ 50] Iter[251/  6]\t\tLoss: 0.9197 Acc@1: 61.566%\n",
            "| Epoch [ 28/ 50] Iter[301/  6]\t\tLoss: 0.8607 Acc@1: 61.571%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 0.7900 Acc@1: 61.24%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8512416542680176 for epoch : 28 ERROR TEST =  0.8512416542680176\n",
            "| Epoch [ 29/ 50] Iter[  1/  6]\t\tLoss: 0.8732 Acc@1: 56.250%\n",
            "| Epoch [ 29/ 50] Iter[ 51/  6]\t\tLoss: 0.8387 Acc@1: 62.163%\n",
            "| Epoch [ 29/ 50] Iter[101/  6]\t\tLoss: 0.8375 Acc@1: 61.897%\n",
            "| Epoch [ 29/ 50] Iter[151/  6]\t\tLoss: 0.7246 Acc@1: 62.003%\n",
            "| Epoch [ 29/ 50] Iter[201/  6]\t\tLoss: 0.8502 Acc@1: 62.072%\n",
            "| Epoch [ 29/ 50] Iter[251/  6]\t\tLoss: 0.8718 Acc@1: 61.865%\n",
            "| Epoch [ 29/ 50] Iter[301/  6]\t\tLoss: 0.8009 Acc@1: 61.877%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 0.7270 Acc@1: 59.69%\n",
            "lr = 0.001\n",
            "| Epoch [ 30/ 50] Iter[  1/  6]\t\tLoss: 0.7937 Acc@1: 62.500%\n",
            "| Epoch [ 30/ 50] Iter[ 51/  6]\t\tLoss: 0.7964 Acc@1: 61.673%\n",
            "| Epoch [ 30/ 50] Iter[101/  6]\t\tLoss: 0.7934 Acc@1: 62.005%\n",
            "| Epoch [ 30/ 50] Iter[151/  6]\t\tLoss: 0.7483 Acc@1: 61.983%\n",
            "| Epoch [ 30/ 50] Iter[201/  6]\t\tLoss: 0.8643 Acc@1: 62.345%\n",
            "| Epoch [ 30/ 50] Iter[251/  6]\t\tLoss: 0.7386 Acc@1: 62.662%\n",
            "| Epoch [ 30/ 50] Iter[301/  6]\t\tLoss: 0.8404 Acc@1: 62.163%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 0.9673 Acc@1: 60.12%\n",
            "lr = 0.001\n",
            "| Epoch [ 31/ 50] Iter[  1/  6]\t\tLoss: 0.8582 Acc@1: 62.500%\n",
            "| Epoch [ 31/ 50] Iter[ 51/  6]\t\tLoss: 0.8651 Acc@1: 62.653%\n",
            "| Epoch [ 31/ 50] Iter[101/  6]\t\tLoss: 0.8722 Acc@1: 62.314%\n",
            "| Epoch [ 31/ 50] Iter[151/  6]\t\tLoss: 0.8481 Acc@1: 62.283%\n",
            "| Epoch [ 31/ 50] Iter[201/  6]\t\tLoss: 0.9214 Acc@1: 62.337%\n",
            "| Epoch [ 31/ 50] Iter[251/  6]\t\tLoss: 0.8422 Acc@1: 62.432%\n",
            "| Epoch [ 31/ 50] Iter[301/  6]\t\tLoss: 0.8707 Acc@1: 62.567%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 0.8477 Acc@1: 60.12%\n",
            "lr = 0.001\n",
            "| Epoch [ 32/ 50] Iter[  1/  6]\t\tLoss: 0.7256 Acc@1: 70.312%\n",
            "| Epoch [ 32/ 50] Iter[ 51/  6]\t\tLoss: 0.8801 Acc@1: 60.815%\n",
            "| Epoch [ 32/ 50] Iter[101/  6]\t\tLoss: 0.9562 Acc@1: 61.417%\n",
            "| Epoch [ 32/ 50] Iter[151/  6]\t\tLoss: 0.7620 Acc@1: 61.838%\n",
            "| Epoch [ 32/ 50] Iter[201/  6]\t\tLoss: 1.0341 Acc@1: 62.135%\n",
            "| Epoch [ 32/ 50] Iter[251/  6]\t\tLoss: 0.9087 Acc@1: 62.108%\n",
            "| Epoch [ 32/ 50] Iter[301/  6]\t\tLoss: 0.7781 Acc@1: 62.100%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 0.7619 Acc@1: 58.15%\n",
            "lr = 0.001\n",
            "| Epoch [ 33/ 50] Iter[  1/  6]\t\tLoss: 0.8334 Acc@1: 62.500%\n",
            "| Epoch [ 33/ 50] Iter[ 51/  6]\t\tLoss: 0.8398 Acc@1: 61.183%\n",
            "| Epoch [ 33/ 50] Iter[101/  6]\t\tLoss: 0.9300 Acc@1: 62.268%\n",
            "| Epoch [ 33/ 50] Iter[151/  6]\t\tLoss: 0.8175 Acc@1: 62.334%\n",
            "| Epoch [ 33/ 50] Iter[201/  6]\t\tLoss: 0.8024 Acc@1: 62.212%\n",
            "| Epoch [ 33/ 50] Iter[251/  6]\t\tLoss: 0.8475 Acc@1: 62.145%\n",
            "| Epoch [ 33/ 50] Iter[301/  6]\t\tLoss: 0.7093 Acc@1: 62.163%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 0.8553 Acc@1: 59.59%\n",
            "lr = 0.001\n",
            "| Epoch [ 34/ 50] Iter[  1/  6]\t\tLoss: 0.8402 Acc@1: 53.125%\n",
            "| Epoch [ 34/ 50] Iter[ 51/  6]\t\tLoss: 0.8328 Acc@1: 60.968%\n",
            "| Epoch [ 34/ 50] Iter[101/  6]\t\tLoss: 0.7179 Acc@1: 61.788%\n",
            "| Epoch [ 34/ 50] Iter[151/  6]\t\tLoss: 0.9151 Acc@1: 62.045%\n",
            "| Epoch [ 34/ 50] Iter[201/  6]\t\tLoss: 0.7688 Acc@1: 62.306%\n",
            "| Epoch [ 34/ 50] Iter[251/  6]\t\tLoss: 0.8933 Acc@1: 62.326%\n",
            "| Epoch [ 34/ 50] Iter[301/  6]\t\tLoss: 0.7987 Acc@1: 62.230%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 0.7834 Acc@1: 61.16%\n",
            "lr = 0.001\n",
            "| Epoch [ 35/ 50] Iter[  1/  6]\t\tLoss: 0.8474 Acc@1: 59.375%\n",
            "| Epoch [ 35/ 50] Iter[ 51/  6]\t\tLoss: 0.8620 Acc@1: 61.826%\n",
            "| Epoch [ 35/ 50] Iter[101/  6]\t\tLoss: 0.8252 Acc@1: 61.974%\n",
            "| Epoch [ 35/ 50] Iter[151/  6]\t\tLoss: 0.8261 Acc@1: 62.438%\n",
            "| Epoch [ 35/ 50] Iter[201/  6]\t\tLoss: 0.8577 Acc@1: 62.189%\n",
            "| Epoch [ 35/ 50] Iter[251/  6]\t\tLoss: 0.8072 Acc@1: 62.095%\n",
            "| Epoch [ 35/ 50] Iter[301/  6]\t\tLoss: 0.7477 Acc@1: 62.209%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 0.7964 Acc@1: 60.89%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8511286758714252 for epoch : 35 ERROR TEST =  0.8511286758714252\n",
            "| Epoch [ 36/ 50] Iter[  1/  6]\t\tLoss: 0.7811 Acc@1: 68.750%\n",
            "| Epoch [ 36/ 50] Iter[ 51/  6]\t\tLoss: 0.7133 Acc@1: 59.559%\n",
            "| Epoch [ 36/ 50] Iter[101/  6]\t\tLoss: 0.9028 Acc@1: 60.566%\n",
            "| Epoch [ 36/ 50] Iter[151/  6]\t\tLoss: 0.9143 Acc@1: 61.300%\n",
            "| Epoch [ 36/ 50] Iter[201/  6]\t\tLoss: 0.7867 Acc@1: 61.318%\n",
            "| Epoch [ 36/ 50] Iter[251/  6]\t\tLoss: 0.7720 Acc@1: 61.666%\n",
            "| Epoch [ 36/ 50] Iter[301/  6]\t\tLoss: 0.8134 Acc@1: 61.867%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 0.9417 Acc@1: 59.02%\n",
            "lr = 0.001\n",
            "| Epoch [ 37/ 50] Iter[  1/  6]\t\tLoss: 0.8260 Acc@1: 62.500%\n",
            "| Epoch [ 37/ 50] Iter[ 51/  6]\t\tLoss: 0.7736 Acc@1: 59.191%\n",
            "| Epoch [ 37/ 50] Iter[101/  6]\t\tLoss: 0.9131 Acc@1: 60.489%\n",
            "| Epoch [ 37/ 50] Iter[151/  6]\t\tLoss: 0.9116 Acc@1: 61.445%\n",
            "| Epoch [ 37/ 50] Iter[201/  6]\t\tLoss: 0.8192 Acc@1: 61.855%\n",
            "| Epoch [ 37/ 50] Iter[251/  6]\t\tLoss: 0.8102 Acc@1: 61.859%\n",
            "| Epoch [ 37/ 50] Iter[301/  6]\t\tLoss: 0.8180 Acc@1: 62.085%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 0.7543 Acc@1: 55.63%\n",
            "lr = 0.001\n",
            "| Epoch [ 38/ 50] Iter[  1/  6]\t\tLoss: 0.9120 Acc@1: 62.500%\n",
            "| Epoch [ 38/ 50] Iter[ 51/  6]\t\tLoss: 0.7229 Acc@1: 61.121%\n",
            "| Epoch [ 38/ 50] Iter[101/  6]\t\tLoss: 0.7487 Acc@1: 60.458%\n",
            "| Epoch [ 38/ 50] Iter[151/  6]\t\tLoss: 0.6853 Acc@1: 61.269%\n",
            "| Epoch [ 38/ 50] Iter[201/  6]\t\tLoss: 0.7181 Acc@1: 61.482%\n",
            "| Epoch [ 38/ 50] Iter[251/  6]\t\tLoss: 0.8737 Acc@1: 61.498%\n",
            "| Epoch [ 38/ 50] Iter[301/  6]\t\tLoss: 0.7509 Acc@1: 61.654%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 0.8266 Acc@1: 61.59%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8457684086428748 for epoch : 38 ERROR TEST =  0.8457684086428748\n",
            "| Epoch [ 39/ 50] Iter[  1/  6]\t\tLoss: 0.7729 Acc@1: 68.750%\n",
            "| Epoch [ 39/ 50] Iter[ 51/  6]\t\tLoss: 0.8131 Acc@1: 61.979%\n",
            "| Epoch [ 39/ 50] Iter[101/  6]\t\tLoss: 0.8085 Acc@1: 62.020%\n",
            "| Epoch [ 39/ 50] Iter[151/  6]\t\tLoss: 0.7536 Acc@1: 61.807%\n",
            "| Epoch [ 39/ 50] Iter[201/  6]\t\tLoss: 0.7693 Acc@1: 61.668%\n",
            "| Epoch [ 39/ 50] Iter[251/  6]\t\tLoss: 0.8047 Acc@1: 61.778%\n",
            "| Epoch [ 39/ 50] Iter[301/  6]\t\tLoss: 0.8068 Acc@1: 62.147%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 1.0149 Acc@1: 57.05%\n",
            "lr = 0.001\n",
            "| Epoch [ 40/ 50] Iter[  1/  6]\t\tLoss: 1.0040 Acc@1: 51.562%\n",
            "| Epoch [ 40/ 50] Iter[ 51/  6]\t\tLoss: 0.8287 Acc@1: 61.826%\n",
            "| Epoch [ 40/ 50] Iter[101/  6]\t\tLoss: 0.7857 Acc@1: 62.268%\n",
            "| Epoch [ 40/ 50] Iter[151/  6]\t\tLoss: 0.7375 Acc@1: 62.510%\n",
            "| Epoch [ 40/ 50] Iter[201/  6]\t\tLoss: 0.7467 Acc@1: 62.749%\n",
            "| Epoch [ 40/ 50] Iter[251/  6]\t\tLoss: 0.9418 Acc@1: 62.712%\n",
            "| Epoch [ 40/ 50] Iter[301/  6]\t\tLoss: 0.8914 Acc@1: 62.557%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 0.8805 Acc@1: 61.37%\n",
            "lr = 0.001\n",
            "| Epoch [ 41/ 50] Iter[  1/  6]\t\tLoss: 0.8130 Acc@1: 70.312%\n",
            "| Epoch [ 41/ 50] Iter[ 51/  6]\t\tLoss: 0.8241 Acc@1: 61.642%\n",
            "| Epoch [ 41/ 50] Iter[101/  6]\t\tLoss: 0.9111 Acc@1: 61.773%\n",
            "| Epoch [ 41/ 50] Iter[151/  6]\t\tLoss: 0.8204 Acc@1: 62.728%\n",
            "| Epoch [ 41/ 50] Iter[201/  6]\t\tLoss: 0.8356 Acc@1: 62.492%\n",
            "| Epoch [ 41/ 50] Iter[251/  6]\t\tLoss: 0.8185 Acc@1: 62.413%\n",
            "| Epoch [ 41/ 50] Iter[301/  6]\t\tLoss: 0.8047 Acc@1: 62.422%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 0.8141 Acc@1: 60.71%\n",
            "lr = 0.001\n",
            "| Epoch [ 42/ 50] Iter[  1/  6]\t\tLoss: 0.6818 Acc@1: 65.625%\n",
            "| Epoch [ 42/ 50] Iter[ 51/  6]\t\tLoss: 0.8404 Acc@1: 61.029%\n",
            "| Epoch [ 42/ 50] Iter[101/  6]\t\tLoss: 0.7777 Acc@1: 62.206%\n",
            "| Epoch [ 42/ 50] Iter[151/  6]\t\tLoss: 0.8261 Acc@1: 62.521%\n",
            "| Epoch [ 42/ 50] Iter[201/  6]\t\tLoss: 0.9482 Acc@1: 62.648%\n",
            "| Epoch [ 42/ 50] Iter[251/  6]\t\tLoss: 0.8125 Acc@1: 62.531%\n",
            "| Epoch [ 42/ 50] Iter[301/  6]\t\tLoss: 0.8529 Acc@1: 62.760%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 0.9911 Acc@1: 61.64%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8449112309349908 for epoch : 42 ERROR TEST =  0.8449112309349908\n",
            "| Epoch [ 43/ 50] Iter[  1/  6]\t\tLoss: 0.8336 Acc@1: 65.625%\n",
            "| Epoch [ 43/ 50] Iter[ 51/  6]\t\tLoss: 0.9412 Acc@1: 61.305%\n",
            "| Epoch [ 43/ 50] Iter[101/  6]\t\tLoss: 0.6784 Acc@1: 61.742%\n",
            "| Epoch [ 43/ 50] Iter[151/  6]\t\tLoss: 0.7967 Acc@1: 62.127%\n",
            "| Epoch [ 43/ 50] Iter[201/  6]\t\tLoss: 0.8131 Acc@1: 62.290%\n",
            "| Epoch [ 43/ 50] Iter[251/  6]\t\tLoss: 0.8560 Acc@1: 62.375%\n",
            "| Epoch [ 43/ 50] Iter[301/  6]\t\tLoss: 0.7050 Acc@1: 62.386%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 0.8902 Acc@1: 61.40%\n",
            "lr = 0.001\n",
            "| Epoch [ 44/ 50] Iter[  1/  6]\t\tLoss: 0.8078 Acc@1: 67.188%\n",
            "| Epoch [ 44/ 50] Iter[ 51/  6]\t\tLoss: 0.9459 Acc@1: 63.082%\n",
            "| Epoch [ 44/ 50] Iter[101/  6]\t\tLoss: 0.7497 Acc@1: 62.314%\n",
            "| Epoch [ 44/ 50] Iter[151/  6]\t\tLoss: 0.7436 Acc@1: 62.521%\n",
            "| Epoch [ 44/ 50] Iter[201/  6]\t\tLoss: 0.7505 Acc@1: 62.469%\n",
            "| Epoch [ 44/ 50] Iter[251/  6]\t\tLoss: 0.8035 Acc@1: 62.537%\n",
            "| Epoch [ 44/ 50] Iter[301/  6]\t\tLoss: 0.8973 Acc@1: 62.375%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 1.1377 Acc@1: 58.69%\n",
            "lr = 0.001\n",
            "| Epoch [ 45/ 50] Iter[  1/  6]\t\tLoss: 0.9120 Acc@1: 53.125%\n",
            "| Epoch [ 45/ 50] Iter[ 51/  6]\t\tLoss: 0.8374 Acc@1: 61.029%\n",
            "| Epoch [ 45/ 50] Iter[101/  6]\t\tLoss: 0.7628 Acc@1: 61.928%\n",
            "| Epoch [ 45/ 50] Iter[151/  6]\t\tLoss: 0.8418 Acc@1: 62.241%\n",
            "| Epoch [ 45/ 50] Iter[201/  6]\t\tLoss: 0.8016 Acc@1: 62.313%\n",
            "| Epoch [ 45/ 50] Iter[251/  6]\t\tLoss: 0.8019 Acc@1: 62.332%\n",
            "| Epoch [ 45/ 50] Iter[301/  6]\t\tLoss: 0.8414 Acc@1: 62.443%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 0.9814 Acc@1: 61.63%\n",
            "lr = 0.001\n",
            "| Epoch [ 46/ 50] Iter[  1/  6]\t\tLoss: 0.8016 Acc@1: 67.188%\n",
            "| Epoch [ 46/ 50] Iter[ 51/  6]\t\tLoss: 0.7702 Acc@1: 63.021%\n",
            "| Epoch [ 46/ 50] Iter[101/  6]\t\tLoss: 1.0336 Acc@1: 62.515%\n",
            "| Epoch [ 46/ 50] Iter[151/  6]\t\tLoss: 0.8787 Acc@1: 62.376%\n",
            "| Epoch [ 46/ 50] Iter[201/  6]\t\tLoss: 0.8693 Acc@1: 62.189%\n",
            "| Epoch [ 46/ 50] Iter[251/  6]\t\tLoss: 0.8379 Acc@1: 62.226%\n",
            "| Epoch [ 46/ 50] Iter[301/  6]\t\tLoss: 0.8609 Acc@1: 62.214%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 0.7877 Acc@1: 61.79%\n",
            "lr = 0.001\n",
            "Best RMSE is of : 0.8415342856336523 for epoch : 46 ERROR TEST =  0.8415342856336523\n",
            "| Epoch [ 47/ 50] Iter[  1/  6]\t\tLoss: 0.7661 Acc@1: 71.875%\n",
            "| Epoch [ 47/ 50] Iter[ 51/  6]\t\tLoss: 0.8377 Acc@1: 60.846%\n",
            "| Epoch [ 47/ 50] Iter[101/  6]\t\tLoss: 0.8775 Acc@1: 62.082%\n",
            "| Epoch [ 47/ 50] Iter[151/  6]\t\tLoss: 0.7858 Acc@1: 62.676%\n",
            "| Epoch [ 47/ 50] Iter[201/  6]\t\tLoss: 0.7769 Acc@1: 62.982%\n",
            "| Epoch [ 47/ 50] Iter[251/  6]\t\tLoss: 0.8713 Acc@1: 62.824%\n",
            "| Epoch [ 47/ 50] Iter[301/  6]\t\tLoss: 0.9200 Acc@1: 62.708%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 0.8081 Acc@1: 61.08%\n",
            "lr = 0.001\n",
            "| Epoch [ 48/ 50] Iter[  1/  6]\t\tLoss: 0.7620 Acc@1: 62.500%\n",
            "| Epoch [ 48/ 50] Iter[ 51/  6]\t\tLoss: 0.7654 Acc@1: 62.224%\n",
            "| Epoch [ 48/ 50] Iter[101/  6]\t\tLoss: 0.8226 Acc@1: 63.134%\n",
            "| Epoch [ 48/ 50] Iter[151/  6]\t\tLoss: 0.8001 Acc@1: 63.224%\n",
            "| Epoch [ 48/ 50] Iter[201/  6]\t\tLoss: 0.7588 Acc@1: 63.161%\n",
            "| Epoch [ 48/ 50] Iter[251/  6]\t\tLoss: 0.7773 Acc@1: 63.172%\n",
            "| Epoch [ 48/ 50] Iter[301/  6]\t\tLoss: 0.8804 Acc@1: 63.009%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 0.7472 Acc@1: 60.41%\n",
            "lr = 0.001\n",
            "| Epoch [ 49/ 50] Iter[  1/  6]\t\tLoss: 0.8179 Acc@1: 62.500%\n",
            "| Epoch [ 49/ 50] Iter[ 51/  6]\t\tLoss: 0.8650 Acc@1: 61.703%\n",
            "| Epoch [ 49/ 50] Iter[101/  6]\t\tLoss: 0.7760 Acc@1: 62.608%\n",
            "| Epoch [ 49/ 50] Iter[151/  6]\t\tLoss: 0.9540 Acc@1: 62.459%\n",
            "| Epoch [ 49/ 50] Iter[201/  6]\t\tLoss: 0.8550 Acc@1: 62.679%\n",
            "| Epoch [ 49/ 50] Iter[251/  6]\t\tLoss: 0.8948 Acc@1: 62.780%\n",
            "| Epoch [ 49/ 50] Iter[301/  6]\t\tLoss: 0.7405 Acc@1: 62.915%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 0.8701 Acc@1: 55.02%\n",
            "lr = 0.001\n",
            "Training Done!\n"
          ]
        }
      ],
      "source": [
        "print (\"Let us Train.\")\n",
        "EPOCHS = 50\n",
        "model = SentimentClassifier(768, NUM_CLASSES).to(device)\n",
        "model_test = SentimentClassifier(768, NUM_CLASSES).to(device)\n",
        "best_error = float('inf')\n",
        "LEARNING_RATE = 1e-3\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau,StepLR\n",
        "\n",
        "traindataset = EmbeddingDataset(train_embeddings, train_y)\n",
        "trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valdataset = EmbeddingDataset(val_embeddings, val_y)\n",
        "valloader = DataLoader(valdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "#lr_scheduler =  StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, 'min', patience=7)\n",
        "\n",
        "train_history = []\n",
        "val_history = []\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "print('3/ training model 1')\n",
        "print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "iter =0\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train(model, trainloader, optimizer, epoch)\n",
        "    train_history.append(loss)\n",
        "    #lr_scheduler.step()\n",
        "    val_loss= test(model, valloader,epoch)\n",
        "    val_history.append(val_loss)\n",
        "    lr_scheduler.step(val_loss)\n",
        "    print('lr =',get_lr(optimizer))\n",
        "\n",
        "    if val_loss <best_error:\n",
        "        best_error=val_loss\n",
        "        print('Best RMSE is of : ' + str(best_error), 'for epoch :', epoch,'ERROR TEST = ',val_loss)\n",
        "        #model_test.parameters()=model.state_dict()\n",
        "        model_test.load_state_dict(model.state_dict(), strict=True)\n",
        "\n",
        "print (\"Training Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUgqW43GU6ne"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-09-12T08:28:24.157868Z",
          "iopub.status.busy": "2024-09-12T08:28:24.157398Z",
          "iopub.status.idle": "2024-09-12T08:28:24.285993Z",
          "shell.execute_reply": "2024-09-12T08:28:24.284901Z",
          "shell.execute_reply.started": "2024-09-12T08:28:24.157825Z"
        },
        "id": "s8_Iuj66dBip",
        "outputId": "c4b9ca89-fb80-4c58-de6a-fb78c24d52fe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================== \n",
            "Test set = \n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 1.0562 Acc@1: 55.29%\n",
            "==================== \n"
          ]
        }
      ],
      "source": [
        "testdataset = TextDataset(test_x,test_y, tokenizer, MAX_LENGTH)\n",
        "testloader = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "# Extract embeddings\n",
        "\n",
        "test_embeddings = extract_embeddings(bert, testloader, device)\n",
        "test_embeddings =test_embeddings.cpu()\n",
        "print('==================== ')\n",
        "print('Test set = ')\n",
        "testdataset = EmbeddingDataset(test_embeddings, test_y)\n",
        "testdataset = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loss,accu = test(model, testdataset,epoch)\n",
        "print('==================== ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkD2ubONd_R2"
      },
      "source": [
        "## Questions\n",
        "\n",
        "**q0/  please analyse the dataset with differents classical machine learning model**\n",
        "\n",
        "**q1/  please perform a classification with differents classical machine learning model and analyse the performences**\n",
        "\n",
        "**q2/  please perform a classification with a MLP?**\n",
        "\n",
        "**q3/  please analyse all the performences and explain which is the best**\n",
        "\n",
        "**q4/  please use an LLM compare your performences to a LLM**\n",
        "\n",
        "**q5/  please explain why I choose a BERT embedding instead of the raw text**\n",
        "\n",
        "**q6/  please read the BERT paper and explain the BERT architecture**\n",
        "\n",
        "**q7/  please finetue with LORA an LLM to classify the sentiment (optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUIRWJllOee8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 989445,
          "sourceId": 1808590,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "llm-sentiment",
      "language": "python",
      "name": "llm-sentiment"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
