\section{Q1---Classification avec des mod\`eles classiques et analyse de performance}
\label{sec:q1}

Au total, 12 configurations exp\'erimentales sont entra\^{\i}n\'ees (3 sch\'emas de vectorisation $\times$ 4 mod\`eles). L'objectif est de comparer ces combinaisons sur l'ensemble de test et de d\'efinir une base classique solide, servant ensuite de r\'ef\'erence face \`a des m\'ethodes bas\'ees sur des embeddings et des mod\`eles de type BERT.

Les m\'etriques rapport\'ees sont l'Accuracy, le Macro-Recall et le Macro-F1. Les m\'etriques macro sont particuli\`erement pertinentes car elles \'evaluent la performance de mani\`ere plus \'equilibr\'ee entre classes, en r\'eduisant le risque qu'une classe dominante pilote l'\'evaluation globale.

\subsection{Temps d'entra\^{\i}nement}
\label{subsec:q1-time}

Chaque exp\'erience bas\'ee sur \texttt{GridSearchCV} produit un fichier CSV contenant le d\'etail de toutes les combinaisons test\'ees, y compris les hyperparam\`etres du vectorizer et du classifieur. Ces CSV permettent une analyse syst\'ematique des changements de configuration et une s\'election inform\'ee de la meilleure cha\^{\i}ne finale.

Dans ces fichiers, le champ \texttt{mean\_fit\_time} repr\'esente le temps moyen d'entra\^{\i}nement par pli pour chaque configuration \'evalu\'ee. Il permet d'estimer le co\^ut total associ\'e \`a la recherche d'hyperparam\`etres.

\subsubsection{Estimation du temps total (calcul s\'equentiel)}
\label{subsubsec:q1-ttotal}

L'estimation s\'equentielle est calcul\'ee comme la somme des temps moyens par pli, multipli\'ee par le nombre de plis de validation crois\'ee :
\begin{equation}
\label{eq:q1-e1}
T_{\text{total}} \approx \sum_{i=1}^{n_{\text{candidates}}} \left(\texttt{mean\_fit\_time}_i \times n_{\text{splits}}\right),
\qquad
n_{\text{splits}} = 5.
\end{equation}

Ici, $n_{\text{candidates}}$ correspond au nombre de lignes du CSV (nombre de combinaisons \'evalu\'ees) :
\begin{itemize}
    \item $n_{\text{candidates}} = 968$
    \item $T_{\text{total}} \approx 287{,}978.76~\text{s}$
\end{itemize}

\subsubsection{Temps mur avec parall\'elisation}
\label{subsubsec:q1-twall}

La valeur pr\'ec\'edente correspond \`a un temps de calcul th\'eorique s\'equentiel. Comme le parall\'elisme est activ\'e avec \texttt{n\_jobs=-1}, la charge est distribu\'ee sur plusieurs c\oe urs CPU. Un temps mur approximatif peut \^etre estim\'e par :
\begin{equation}
\label{eq:q1-e2}
T_{\text{wall}} \approx \frac{T_{\text{total}}}{n_{\text{jobs}}}.
\end{equation}

En supposant 8 c\oe urs effectifs :
\[
T_{\text{wall}} \approx \frac{287{,}978.76}{8} \approx 35{,}997.35~\text{s} \approx 10.00~\text{h}.
\]

\subsection{Performance sur l'ensemble de test}
\label{subsec:q1-test}

La performance sur test est r\'esum\'ee par les r\'esultats pr\'esent\'es dans les Figs.~\ref{fig:q1-f1}--\ref{fig:q1-f3}. Le Macro-F1, le Macro-Recall et l'Accuracy sont rapport\'es dans les Figs.~\ref{fig:q1-f1}, \ref{fig:q1-f2} et \ref{fig:q1-f3}, respectivement. Pour chaque classifieur, les graphiques comparent les scores obtenus avec chaque m\'ethode de vectorisation, ce qui rend les tendances faciles \`a identifier.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q1/barh_models_hue_vectorization_f1_macro.png}
  \caption{Comparaison sur test --- Macro-F1 (couleur = vectorisation).}
  \label{fig:q1-f1}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q1/barh_models_hue_vectorization_recall_macro.png}
  \caption{Comparaison sur test --- Macro-Recall (couleur = vectorisation).}
  \label{fig:q1-f2}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q1/barh_models_hue_vectorization_accuracy.png}
  \caption{Comparaison sur test --- Accuracy (couleur = vectorisation).}
  \label{fig:q1-f3}
\end{figure}

\subsubsection{Impact de la m\'ethode de vectorisation}
\label{subsubsec:q1-vectorization}

Globalement, les figures indiquent que TF--IDF caract\`eres (TF--IDF char) tend \`a fournir les meilleures valeurs sur les trois m\'etriques. Ce comportement est coh\'erent avec la nature des tweets (courts, informels), o\`u la mod\'elisation au niveau caract\`ere capture des signaux sub-lexicaux importants : fautes d'orthographe, variations morphologiques, allongements (ex. ``soooo good''), hashtags, abr\'eviations, et indices pr\'efixe/suffixe.

\subsubsection{Comparaison des mod\`eles et compromis}
\label{subsubsec:q1-tradeoffs}

Parmi les classifieurs, le SVM lin\'eaire et la r\'egression logistique se distinguent par leur constance, en particulier combin\'es \`a TF--IDF (notamment TF--IDF char). Les repr\'esentations BoW/TF--IDF produisant des matrices de tr\`es grande dimension et creuses, les mod\`eles lin\'eaires sont g\'en\'eralement efficaces et peu co\^uteux.

Bien que Random Forest soit tr\`es comp\'etitif (voire meilleur), plusieurs limites sont importantes en haute dimension :
\begin{itemize}
    \item \textbf{Scalabilit\'e et co\^ut :} l'entra\^{\i}nement de nombreux arbres dans un espace TF--IDF augmente fortement le temps et la m\'emoire, surtout sous \texttt{GridSearchCV}.
    \item \textbf{Risque de sur-apprentissage :} TF--IDF char introduit de nombreux n-grammes tr\`es sp\'ecifiques ; un mod\`ele non-lin\'eaire peut capturer des motifs accidentels et d\'egrader la robustesse hors-domaine.
    \item \textbf{Interpr\'etabilit\'e pratique plus faible :} une for\^et est plus difficile \`a justifier qu'un mod\`ele lin\'eaire.
\end{itemize}

Ainsi, m\^eme en cas de gain marginal, les mod\`eles lin\'eaires restent attractifs pour leur stabilit\'e, leur co\^ut et leur clart\'e m\'ethodologique.