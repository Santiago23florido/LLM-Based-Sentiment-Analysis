{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q1 - Char TF-IDF (char_wb)\n",
        "\n",
        "Fixed structure: Vectorization, After vectorization cleaning, Modeling, Results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Vectorization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Local helpers shared across vectorization notebooks\n",
        "ROOT_DIR = Path.cwd()\n",
        "if (ROOT_DIR / 'Q1').exists():\n",
        "    DATA_DIR = ROOT_DIR\n",
        "    FUNCTIONS_DIR = ROOT_DIR / 'Q1' / 'functions'\n",
        "else:\n",
        "    DATA_DIR = ROOT_DIR.parent\n",
        "    FUNCTIONS_DIR = ROOT_DIR / 'functions'\n",
        "\n",
        "sys.path.insert(0, str(FUNCTIONS_DIR))\n",
        "\n",
        "from common import (\n",
        "    load_dataset,\n",
        "    pick_first_existing,\n",
        "    train_val_split,\n",
        "    clean_after_vectorization,\n",
        "    compute_metrics,\n",
        ")\n",
        "\n",
        "# Load processed data\n",
        "train_df = load_dataset(DATA_DIR / 'train_df_processed.csv')\n",
        "test_df = load_dataset(DATA_DIR / 'test_df_processed.csv')\n",
        "\n",
        "text_col = pick_first_existing(train_df, ['processed_text', 'text'])\n",
        "label_col = pick_first_existing(train_df, ['sentiment', 'sentiment_class'])\n",
        "\n",
        "X = train_df[text_col].fillna('').astype(str)\n",
        "y = train_df[label_col]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_val_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Keep raw text for error analysis later\n",
        "X_train_text = X_train.copy()\n",
        "X_val_text = X_val.copy()\n",
        "\n",
        "# Char-level TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(\n",
        "    analyzer='char_wb',\n",
        "    ngram_range=(3, 5),\n",
        "    min_df=2,\n",
        "    max_df=0.9,\n",
        "    sublinear_tf=True,\n",
        ")\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_val_vec = vectorizer.transform(X_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. After vectorization cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Remove rows with empty vectors (all-zero features)\n",
        "X_train_vec, y_train, X_train_text, train_mask = clean_after_vectorization(\n",
        "    X_train_vec, y_train, X_train_text\n",
        ")\n",
        "X_val_vec, y_val, X_val_text, val_mask = clean_after_vectorization(\n",
        "    X_val_vec, y_val, X_val_text\n",
        ")\n",
        "\n",
        "print('Removed train rows:', (~train_mask).sum())\n",
        "print('Removed val rows:', (~val_mask).sum())\n",
        "print('Train size after cleaning:', X_train_vec.shape[0])\n",
        "print('Val size after cleaning:', X_val_vec.shape[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Define models directly in the notebook\n",
        "models = {\n",
        "    'MultinomialNB': MultinomialNB(alpha=1.0),\n",
        "    'LogisticRegression': LogisticRegression(\n",
        "        C=1.0,\n",
        "        solver='liblinear',\n",
        "        max_iter=2000,\n",
        "        random_state=42,\n",
        "    ),\n",
        "    'LinearSVC': LinearSVC(C=1.0),\n",
        "    'SGDClassifier': SGDClassifier(\n",
        "        loss='hinge',\n",
        "        alpha=1e-4,\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "    ),\n",
        "}\n",
        "\n",
        "results = []\n",
        "preds_by_model = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_vec, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    preds = model.predict(X_val_vec)\n",
        "    preds_by_model[name] = preds\n",
        "\n",
        "    metrics = compute_metrics(y_val, preds)\n",
        "    metrics['model'] = name\n",
        "    metrics['train_time_sec'] = train_time\n",
        "    results.append(metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Results table\n",
        "results_df = pd.DataFrame(results).sort_values('macro_f1', ascending=False)\n",
        "display(results_df)\n",
        "\n",
        "# Confusion matrices for the top two models\n",
        "top_models = results_df.head(2)['model'].tolist()\n",
        "for model_name in top_models:\n",
        "    preds = preds_by_model[model_name]\n",
        "    disp = ConfusionMatrixDisplay.from_predictions(\n",
        "        y_val,\n",
        "        preds,\n",
        "        cmap='Blues',\n",
        "        colorbar=False,\n",
        "    )\n",
        "    disp.ax_.set_title(f'Confusion Matrix - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "# Misclassified examples from the best model\n",
        "best_model = top_models[0]\n",
        "errors = pd.DataFrame({\n",
        "    'text': X_val_text,\n",
        "    'true_label': y_val,\n",
        "    'pred_label': preds_by_model[best_model],\n",
        "})\n",
        "errors = errors[errors['true_label'] != errors['pred_label']].head(10)\n",
        "display(errors)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}