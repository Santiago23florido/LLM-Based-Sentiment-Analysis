\section{Q3---Analyse comparative des performances MLP et implications pour la s\'election de baseline}
\label{sec:q3}

Cette section propose une analyse interpr\'etative des r\'esultats MLP introduits en Q2. Bien que Q1 se concentre sur des baselines classiques, il est utile d'\'evaluer si l'introduction de non-lin\'earit\'e via des MLP apporte un gain significatif, et quelles familles de repr\'esentations en b\'en\'eficient. L'analyse s'appuie sur le Macro-F1, le Macro-Recall et l'Accuracy sur test, compl\'et\'es par l'inspection des m\'etriques d'entra\^{\i}nement afin de caract\'eriser les \'ecarts train--test.

\subsection{Analyse pr\'eliminaire des MLP (Q2)}
\label{subsec:q3-mlp-prelim}

Les r\'esultats sur test pour Macro-F1, Macro-Recall et Accuracy sont pr\'esent\'es en Fig.~\ref{fig:q3-mlp-test-f1}, Fig.~\ref{fig:q3-mlp-test-recall} et Fig.~\ref{fig:q3-mlp-test-acc}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q3/mlp_test_f1_macro_barh_hue.png}
  \caption{Comparaison MLP sur test --- Macro-F1 (couleur = famille de repr\'esentation).}
  \label{fig:q3-mlp-test-f1}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q3/mlp_test_recall_macro_barh_hue.png}
  \caption{Comparaison MLP sur test --- Macro-Recall (couleur = famille de repr\'esentation).}
  \label{fig:q3-mlp-test-recall}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q3/mlp_test_accuracy_barh_hue.png}
  \caption{Comparaison MLP sur test --- Accuracy (couleur = famille de repr\'esentation).}
  \label{fig:q3-mlp-test-acc}
\end{figure}

Une tendance stable ressort : les configurations bas\'ees sur \textbf{Char TF--IDF} dominent la performance des MLP. En particulier, le MLP Char TF--IDF (4096--2048--1024, dropout 0.10, ReLU) atteint les meilleurs scores (Macro-F1 = 0.711, Macro-Recall = 0.706, Accuracy = 0.708). Une variante (1024--512--256, dropout 0.30, ReLU) reste proche (0.702 / 0.701 / 0.699). Cela sugg\`ere que, pour des tweets, les signaux au niveau caract\`ere (abr\'eviations, variations orthographiques, motifs suffixe/pr\'efixe, langage informel) restent tr\`es informatifs, y compris avec un classifieur non-lin\'eaire.

Les familles \textbf{BoW} et \textbf{TF--IDF mot} constituent un second niveau, avec des meilleurs cas autour de 0.67--0.68. Enfin, les variantes \textbf{BERT} (t\^etes MLP au-dessus d'embeddings fig\'es) restent comp\'etitives mais plus limit\'ees dans ce r\'egime (environ 0.65--0.67), ce qui est coh\'erent avec l'utilisation d'embeddings contextualis\'es sans fine-tuning end-to-end de l'encodeur.

\subsection{Comparaison par familles (qualit\'e pr\'edictive)}
\label{subsec:q3-mlp-families}

La comparaison au niveau des familles est coh\'erente sur les trois m\'etriques : \textbf{Char TF--IDF} produit les MLP les plus performants et de mani\`ere r\'eguli\`ere.

\subsubsection{Char TF--IDF (meilleure famille en performance)}
\label{subsubsec:q3-char-tfidf}

Les MLP Char TF--IDF atteignent les meilleures performances. Le meilleur mod\`ele est Char TF--IDF 4096--2048--1024 (dropout 0.10, ReLU) avec Macro-F1 $\approx 0.711$, Macro-Recall $\approx 0.706$ et Accuracy $\approx 0.708$. Le comportement est coh\'erent avec le domaine tweet : la granularit\'e caract\`ere est robuste aux fautes, abr\'eviations, allongements (ex. ``soooo''), hashtags et variations d'\'ecriture.

\subsubsection{BoW et TF--IDF mot (niveau interm\'ediaire)}
\label{subsubsec:q3-bow-word}

Les MLP BoW et TF--IDF mot sous-performent Char TF--IDF. Le meilleur cas BoW atteint environ Macro-F1 $\approx 0.678$, et le meilleur cas TF--IDF mot environ Macro-F1 $\approx 0.670$. Sur des textes tr\`es courts, la pr\'esence/absence de termes saillants (BoW) peut \^etre aussi utile qu'une pond\'eration de raret\'e au niveau mot, tandis que les repr\'esentations mot restent sensibles au bruit orthographique.

\subsubsection{BERT (comp\'etitif mais non sup\'erieur \`a Char TF--IDF dans ce r\'egime)}
\label{subsubsec:q3-bert}

Pour les mod\`eles BERT, le meilleur r\'esultat est obtenu par l'option la plus simple : BERT + t\^ete lin\'eaire (768$\rightarrow$3), avec Macro-F1 $\approx 0.666$. L'ajout de couches MLP au-dessus des embeddings n'am\'eliore pas les performances et tend \`a les d\'egrader l\'eg\`erement. Une interpr\'etation coh\'erente est que l'espace d'embeddings BERT est d\'ej\`a raisonnablement s\'eparable lin\'eairement, et qu'augmenter la capacit\'e de la t\^ete ajoute des param\`etres qui ne se traduisent pas en meilleure g\'en\'eralisation dans ce r\'egime.

Pour caract\'eriser la g\'en\'eralisation, les m\'etriques d'entra\^{\i}nement sont examin\'ees (Figs.~\ref{fig:q3-mlp-train-acc}--\ref{fig:q3-mlp-train-recall}).

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q3/mlp_train_accuracy_barh_hue.png}
  \caption{Comparaison MLP sur train --- Accuracy (couleur = famille de repr\'esentation).}
  \label{fig:q3-mlp-train-acc}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q3/mlp_train_f1_macro_barh_hue.png}
  \caption{Comparaison MLP sur train --- Macro-F1 (couleur = famille de repr\'esentation).}
  \label{fig:q3-mlp-train-f1}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{images/Q3/mlp_train_recall_macro_barh_hue.png}
  \caption{Comparaison MLP sur train --- Macro-Recall (couleur = famille de repr\'esentation).}
  \label{fig:q3-mlp-train-recall}
\end{figure}

Ces figures mettent en \'evidence un ph\'enom\`ene important : les MLP sur BoW/TF--IDF (mot ou caract\`ere) atteignent souvent des scores tr\`es \'elev\'es sur train (parfois proches de 1.0), m\^eme pour des architectures modestes. Cela indique une forte capacit\'e d'ajustement dans des espaces creux et de grande dimension. Toutefois, ce plafonnement sur train ne garantit pas un gain proportionnel sur test : un \'ecart train--test demeure, ce qui justifie d'interpr\'eter ces r\'esultats comme un compromis (capacit\'e \'elev\'ee mais risque structurel de sur-apprentissage).

Ainsi, le meilleur MLP en performance sur test est Char TF--IDF 4096--2048--1024 (dropout 0.10). Il surpasse la meilleure variante BERT (t\^ete lin\'eaire). N\'eanmoins, du point de vue g\'en\'eralisation, les MLP sur TF--IDF requi\`erent un contr\^ole explicite (r\'egularisation, arr\^et anticip\'e, contr\^ole de capacit\'e effective). En comparaison, BERT + t\^ete lin\'eaire constitue une alternative plus conservatrice : performance plus basse, mais structure plus simple et moins sensible \`a l'augmentation de capacit\'e de la t\^ete.